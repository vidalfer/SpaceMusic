# ğŸ›ï¸ Gesture-Flow DJ

Uma interface web de performance musical em tempo real onde o usuÃ¡rio atua como um maestro de IA, controlando a mÃºsica atravÃ©s de gestos manuais detectados via webcam.

![Gesture-Flow DJ](https://img.shields.io/badge/React-18.2-61DAFB?logo=react)
![Three.js](https://img.shields.io/badge/Three.js-0.161-000000?logo=three.js)
![MediaPipe](https://img.shields.io/badge/MediaPipe-Hands-4285F4?logo=google)
![Tone.js](https://img.shields.io/badge/Tone.js-15.0-FF6B6B)

## ğŸ¯ VisÃ£o Geral

O **Gesture-Flow DJ** Ã© uma demo interativa que replica a sensaÃ§Ã£o do "MusicFX DJ" do Google, mas controlada inteiramente por gestos manuais via webcam. O sistema usa **MediaPipe** para detecÃ§Ã£o de mÃ£os em tempo real, **React Three Fiber** para visualizaÃ§Ã£o 3D imersiva, e **Tone.js** para processamento de Ã¡udio com latÃªncia zero.

### O Conceito: "Latency Hiding"

O segredo do MusicFX DJ Ã© dar feedback **imediato** ao usuÃ¡rio enquanto a IA gera o novo Ã¡udio em background:

1. **Feedback InstantÃ¢neo (0ms)**: Filtros e volume sÃ£o controlados em tempo real pelo gesto
2. **GeraÃ§Ã£o AI (2-3s)**: A API Lyria gera o novo loop em background
3. **TransiÃ§Ã£o Seamless**: O novo Ã¡udio Ã© sincronizado no prÃ³ximo compasso

## ğŸš€ Quick Start

### Frontend

```bash
# Instale as dependÃªncias
npm install

# Inicie o servidor de desenvolvimento
npm run dev
```

Acesse `http://localhost:5173`

### Backend (Opcional - para geraÃ§Ã£o AI real)

```bash
cd backend

# Crie um ambiente virtual
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Instale as dependÃªncias
pip install -r requirements.txt

# Configure sua API key
# Copie env.example.txt para .env e adicione sua GEMINI_API_KEY

# Inicie o servidor
uvicorn main:app --reload --port 8000
```

## ğŸ® Como Usar

1. **Permita acesso Ã  webcam** quando solicitado
2. **Clique em "Initialize Audio"** (necessÃ¡rio para ativar o Ã¡udio no navegador)
3. **Posicione sua mÃ£o** na frente da cÃ¢mera
4. **FaÃ§a o gesto de pinÃ§a** (polegar + indicador juntos) para agarrar um orbe
5. **Arraste o orbe** e observe os efeitos:
   - **Eixo Y (altura)**: Controla o Volume/Intensidade
   - **Eixo X (lateral)**: Controla o Filtro (LowPass)
6. **Solte no centro** para ativar a geraÃ§Ã£o de Ã¡udio

### Feedback Visual

| Estado | Cor | Significado |
|--------|-----|-------------|
| Idle | ğŸ”µ Azul/Original | Orbe inativo |
| Grabbed | ğŸŸ£ Magenta | Orbe sendo arrastado |
| Loading | ğŸŸ¡ Amarelo | IA gerando Ã¡udio |
| Ready | ğŸŸ¢ Verde | Ãudio pronto! |

## ğŸ—ï¸ Arquitetura

```
gesture-flow-dj/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Scene.jsx          # Cena 3D principal
â”‚   â”‚   â”œâ”€â”€ SoundOrb.jsx       # Orbes interativos com fÃ­sica
â”‚   â”‚   â”œâ”€â”€ HandCursor.jsx     # Cursor 3D da mÃ£o
â”‚   â”‚   â”œâ”€â”€ AudioControls.jsx  # Painel de controle de Ã¡udio
â”‚   â”‚   â”œâ”€â”€ UIOverlay.jsx      # Interface de status
â”‚   â”‚   â””â”€â”€ WebcamFeed.jsx     # Preview da webcam
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useHandTracking.js   # MediaPipe + LERP smoothing
â”‚   â”‚   â”œâ”€â”€ useAudioEngine.js    # Tone.js DSP engine
â”‚   â”‚   â””â”€â”€ useLyriaRealtime.js  # WebSocket para Lyria API
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ audioService.js      # API client
â”‚   â””â”€â”€ store/
â”‚       â””â”€â”€ appStore.js          # Estado global (Zustand)
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                  # FastAPI server
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ public/
    â””â”€â”€ samples/                 # Loops de Ã¡udio de teste
```

## ğŸ› ï¸ Stack TecnolÃ³gica

### Frontend
| Tecnologia | Uso |
|------------|-----|
| **React + Vite** | Framework e bundler |
| **React Three Fiber** | RenderizaÃ§Ã£o 3D |
| **@react-three/drei** | Helpers para R3F |
| **MediaPipe Hands** | DetecÃ§Ã£o de gestos |
| **Tone.js** | Audio engine com DSP |
| **Zustand** | Gerenciamento de estado |

### Backend
| Tecnologia | Uso |
|------------|-----|
| **FastAPI** | API REST + WebSocket |
| **google-genai** | SDK para Lyria API |
| **uvicorn** | ASGI server |

## ğŸµ IntegraÃ§Ã£o com Google Lyria

O projeto estÃ¡ preparado para integraÃ§Ã£o com a [API Lyria RealTime](https://ai.google.dev/gemini-api/docs/music-generation):

```python
# backend/main.py - Exemplo de uso
from google import genai
from google.genai import types

client = genai.Client(http_options={'api_version': 'v1alpha'})

async with client.aio.live.music.connect(model='models/lyria-realtime-exp') as session:
    await session.set_weighted_prompts(prompts=[
        types.WeightedPrompt(text='minimal techno', weight=1.0),
    ])
    await session.set_music_generation_config(
        config=types.LiveMusicGenerationConfig(bpm=120, temperature=1.0)
    )
    await session.play()
```

### ParÃ¢metros Lyria mapeados para gestos:

| Gesto | ParÃ¢metro Lyria | Range |
|-------|-----------------|-------|
| MÃ£o Y (altura) | `density` | 0.0 - 1.0 |
| MÃ£o X (lateral) | `brightness` | 0.0 - 1.0 |
| Zona extrema Y | Prompt: "intense, powerful" | - |
| Zona extrema X | Prompt: "complex, syncopated" | - |

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

Crie um arquivo `.env` no diretÃ³rio `backend/`:

```env
GEMINI_API_KEY=your_api_key_here
```

Obtenha sua API key em: https://aistudio.google.com/app/apikey

### Samples de Ãudio

Para testar sem a API Lyria, coloque arquivos de Ã¡udio em `public/samples/`:
- `drums.mp3` - Loop de bateria
- `bass.mp3` - Loop de baixo
- `synth.mp3` - Pad de sintetizador
- `fx.mp3` - Efeitos/risers
- `melody.mp3` - Melodia/arpejo

## ğŸ“š ReferÃªncias

- [Google Lyria RealTime](https://ai.google.dev/gemini-api/docs/music-generation?hl=pt-br)
- [MediaPipe Hands](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker)
- [React Three Fiber](https://docs.pmnd.rs/react-three-fiber)
- [Tone.js](https://tonejs.github.io/)

## ğŸ“„ LicenÃ§a

MIT Â© 2026
